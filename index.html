<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Heterogeneous Embodied Multi-Agent Collaboration">
  <meta name="keywords" content="Embodied Multi-Agent Collaboration, Heterogeneous Agents, Embodied Visual Tasks, Group-based Communication,
  Tidying-up Task">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Heterogeneous Embodied Multi-Agent Collaboration</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Heterogeneous Embodied Multi-Agent Collaboration</h1>
          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://keunhong.com">Keunhong Park</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://utkarshsinha.com">Utkarsh Sinha</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://jonbarron.info">Jonathan T. Barron</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="http://sofienbouaziz.com">Sofien Bouaziz</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.danbgoldman.com">Dan B Goldman</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a><sup>2</sup>
            </span>
          </div> -->

          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Washington,</span>
            <span class="author-block"><sup>2</sup>Google Research</span>
          </div> -->

          <!-- <div class="column has-text-centered"> -->
            <!-- <div class="publication-links"> -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->

              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span> -->
            <!-- </div> -->
          <!-- </div> -->
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Multi-agent embodied tasks have recently been studied in complex indoor visual environments. Collaboration among multiple agents can improve work efficiency 
            and has significant practical value. However, most of the existing research focuses on homogeneous multi-agent tasks. Compared with homogeneous agents, 
            heterogeneous agents can leverage their different capabilities to allocate corresponding sub-tasks and cooperate to complete complex tasks. 
            Heterogeneous multi-agent tasks are common in real-world scenarios, and the collaboration strategy among heterogeneous agents is a challenging and 
            important problem to be solved. To study collaboration among heterogeneous agents, we propose the heterogeneous multi-agent tidying-up task, in which multiple 
            heterogeneous agents with different capabilities collaborate with each other to detect misplaced objects and place them in reasonable locations. 
            This is a demanding task since it requires agents to make the best use of their different capabilities to conduct reasonable task planning and complete the whole 
            task. To solve this task, we build a heterogeneous multi-agent tidying-up benchmark dataset in a large number of houses with multiple rooms based on ProcTHOR-10K. 
            We propose the hierarchical decision model based on misplaced object detection, reasonable receptacle prediction, as well as the handshake-based group communication 
            mechanism. Extensive experiments are conducted to demonstrate the effectiveness of the proposed model.
          </p>

          <img src="./static/images/intro_new.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."
                 style="height: 385px; width: auto; display:block; margin:auto;"/>

        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Dataset</h2>
        <div class="content has-text-justified">
          <p>
            To study the collaboration among heterogeneous agents, we propose the heterogeneous embodied multi-agent tidying-up task. 
            We also provide a program to generate the benchmark dataset for this task in ProcTHOR-10K, and the process of generating it 
            from the original scene in ProcTHOR-10K is shown as follows. For each sample in the dataset, 
            we randomly select k objects from the original house in ProcTHOR-10K and then change their current 
            locations to unreasonable receptacles or unreasonable rooms to generate the task data.
          </p>

          <img src="./static/images/process_new.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
        </div>
      </div>
    </div>
    <!--/ Method -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Method -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method Overview</h2>
        <div class="content has-text-justified">
          <p>
            The proposed model consists of four main modules: the misplaced object detector, the reasonable receptacle predictor, 
            the communication module, and the hierarchical decision. The overview of this model is shown as follows. The misplaced object detector judges whether 
            there exists an object placed in an unreasonable location. The reasonable receptacle predictor generates a reasonable receptacle and room type to place the 
            misplaced objects. The communication module transmits the communication information to other heterogeneous agents. The hierarchical decision module predicts 
            the next sub-task, sub-goal, and next actions for each agent to execute.
          </p>

          <img src="./static/images/model.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
        </div>
      </div>
    </div>
    <!--/ Method -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Qualitative Results</h2>

        <h3 class="title is-4">Setting I </h3>
        <div class="content has-text-justified">
          <p>
            In Setting I, three agents with the same visual perceprion ability but different action abilities and morphological characteristics. 
            Agent 1 only has the navigation ability with the low height. Agent 2 only has the navigation ability and its height is high. 
            Agent 3 has both the navigation and manipulation abilities and its height is high. The videos of results in the Single-Room scene and the Cross-Room scene are shown as follows respectively.
          </p>
        </div>

        <div class="column">
          <div class="content">
            <h4 class="title is-5">Single-Room Sample</h4>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/Single_SettingI.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
  
        <div class="column">
          <h4 class="title is-5">Cross-Room Sample</h4>
          <div class="columns is-centered">
            <div class="column content">
              <video id="matting-video" controls playsinline height="100%">
                <source src="./static/videos/Cross_SettingI.mp4"
                        type="video/mp4">
              </video>
            </div>
  
          </div>
        </div>


        <h3 class="title is-4">Setting II</h3>
        <div class="content has-text-justified">
          <p>
            In Setting II, four agents with the same visual perceprion ability but different action abilities and morphological characteristics. 
            Agent 1 only has the navigation ability with the low height. Agent 2 only has the navigation ability and its height is high. 
            Agent 3 has both the navigation and manipulation abilities and its height is high. Agent 4 has the same abilities with Agent 3. 
            The videos of results in the Single-Room scene and the Cross-Room scene are shown as follows respectively.
          </p>
        </div>

        <div class="column">
          <div class="content">
            <h4 class="title is-5">Single-Room Sample</h4>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/Single_SettingII.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
  
        <div class="column">
          <h4 class="title is-5">Cross-Room Sample</h4>
          <div class="columns is-centered">
            <div class="column content">
              <video id="matting-video" controls playsinline height="100%">
                <source src="./static/videos/Cross_SettingII.mp4"
                        type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      
      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author  = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title   = {Nerfies: Deformable Neural Radiance Fields},
  journal = {ICCV},
  year    = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is constructed using the source code provided by <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, and we are grateful for their template.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
